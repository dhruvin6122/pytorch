{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnmhL/08O9e/oo4dhYWj9x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvin6122/pytorch/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpTxy_dIosIS",
        "outputId": "06840da6-9e38-4cda-a982-78c33faced9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 38.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.09MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.53MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Transform: convert images to tensor + flatten later\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                 # to tensor [0,1]\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # flatten 28x28 -> 784\n",
        "])\n",
        "\n",
        "# Train & Test datasets\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(784, 256),  # input: 28x28=784\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)    # 10 classes\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP().to(device)\n"
      ],
      "metadata": {
        "id": "dVTdmy7are45"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()            # multi-class\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "334Jc0m0r67Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        # Forward\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "        total_correct += (logits.argmax(1) == yb).sum().item()\n",
        "\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            total_correct += (logits.argmax(1) == yb).sum().item()\n",
        "\n",
        "    return total_loss/len(loader.dataset), total_correct/len(loader.dataset)\n"
      ],
      "metadata": {
        "id": "gRhSYD--sPMj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch}: \"\n",
        "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acQUTKZWw0Xr",
        "outputId": "08173bbf-df62-4db1-95eb-007a3bdf6252"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train loss=0.3040, acc=0.9116 | Test loss=0.1327, acc=0.9595\n",
            "Epoch 2: Train loss=0.1269, acc=0.9617 | Test loss=0.0974, acc=0.9688\n",
            "Epoch 3: Train loss=0.0903, acc=0.9714 | Test loss=0.0780, acc=0.9751\n",
            "Epoch 4: Train loss=0.0710, acc=0.9774 | Test loss=0.0716, acc=0.9783\n",
            "Epoch 5: Train loss=0.0593, acc=0.9811 | Test loss=0.0704, acc=0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_Model.pt\")\n",
        "\n",
        "torch.save(model, \"mnist_handwritten_digits.pth\")\n"
      ],
      "metadata": {
        "id": "EENZJVAhz3BS"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}